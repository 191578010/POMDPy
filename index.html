<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>POMDPy by pemami4911</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">POMDPy</h1>
      <h2 class="project-tagline">POMDPs in Python</h2>
      <a href="https://github.com/pemami4911/POMDPy" class="btn">View on GitHub</a>
      <a href="https://github.com/pemami4911/POMDPy/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/pemami4911/POMDPy/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="pomdpy" class="anchor" href="#pomdpy" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>POMDPy</h2>

<p><img src="https://travis-ci.org/pemami4911/POMDPy.svg?branch=master" alt="Build">  <img src="https://img.shields.io/badge/python-2.7-blue.svg" alt="Python27">  <img src="https://img.shields.io/badge/python-3.5-blue.svg" alt="Python35"></p>

<p>This open-source project contains a framework for implementing discrete action/state POMDPs in Python. This work was inspired by <a href="http://robotics.itee.uq.edu.au/%7Ehannakur/dokuwiki/doku.php?id=wiki:tapir">TAPIR</a> and the <a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Applications.html">POMCP</a> algorithm.</p>

<p><a href="http://www.pomdp.org/tutorial/index.shtml">What the heck is a POMDP?</a></p>

<p>Here's David Silver and Joel Veness's paper on POMCP, a ground-breaking POMDP solver. <a href="http://papers.nips.cc/paper/4031-monte-carlo-planning-in-large-pomdps.pdf">Monte-Carlo Planning in Large POMDPs</a></p>

<p>This project has been conducted strictly for research purposes. If you would like to contribute to POMDPy or if you have any comments or suggestions, feel free to send me a pull request or send me an email at <a href="mailto:pemami@ufl.edu">pemami@ufl.edu</a>.  </p>

<h2>
<a id="dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

<p>Download the files as a zip or clone into the repository.</p>

<pre><code>git clone https://github.com/pemami4911/POMDPy.git
</code></pre>

<p>This project uses:</p>

<ul>
<li>numpy &gt;= 1.11</li>
<li>matplotlib &gt;= 1.4.3</li>
<li>scipy &gt;= 0.15.1</li>
<li>future &gt;= 0.16</li>
<li>tensorflow &gt;= 0.12</li>
</ul>

<p>See the <a href="https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#download-and-setup">Tensorflow docs</a> for information about installing Tensorflow. </p>

<p>The easiest way to satisfy the dependencies is to use Anaconda. You might have to run <code>pip install --upgrade future</code> after installing Anaconda, however. </p>

<h2>
<a id="supported-solvers" class="anchor" href="#supported-solvers" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Supported Solvers</h2>

<ul>
<li><a href="https://github.com/pemami4911/POMDPy/blob/master/pomdpy/solvers/pomcp.py">POMCP</a></li>
<li><a href="https://github.com/pemami4911/POMDPy/blob/master/pomdpy/solvers/sarsa.py">SARSA</a></li>
<li><a href="https://github.com/pemami4911/POMDPy/blob/master/pomdpy/solvers/value_iteration.py">Value Iteration</a></li>
</ul>

<p>The main difference between POMCP and SARSA is that POMCP uses the off-policy Q-Learning
algorithm and the UCT action-selection strategy. SARSA uses an on-policy variant of TD-Learning. <strong>Both algorithms 
encode the action-value function as a belief search tree.</strong> POMCP is an anytime planner that approximates the action-value
estimates of the current belief via Monte-Carlo simulations before taking a step. This is known as Monte-Carlo Tree Search (MCTS).
SARSA is episodic, in that the agent repeatedly carries out full episodes 
and uses the generated history of experiences to back-up the action-value estimates up the taken path to the root of the belief tree. </p>

<p>I have also implemented exact Value Iteration with Lark's pruning algorithm. This can only be used on the Tiger Problem. </p>

<h2>
<a id="running-an-example" class="anchor" href="#running-an-example" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running an example</h2>

<p>Currently, you can test POMCP and SARSA on the classic Tiger and RockSample POMDPs. </p>

<p>You can optionally edit the RockSample configuration file <code>rock_problem_config.json</code> to change the map size or environment parameters.
This file is located in <code>pompdy/config</code>.
The following maps are available:</p>

<ul>
<li>RockSample(7, 8), a 7 x 7 grid with 8 rocks.</li>
<li>RockSample(11, 11), an 11 x 11 grid with 11 rocks</li>
<li>RockSample(15, 15), a 15 x 15 grid with 15 rocks</li>
<li>As well as a few others, such as (7, 2), (7, 3), (12, 12), and more. It is fairly easy to make new maps.</li>
</ul>

<p>To run the RockSample problem with POMCP:</p>

<pre><code>./main.py --env RockProblem --solver POMCP --max_steps 200 --epsilon_start 1.0 --epsilon_decay 0.01 --n_runs 10 --n_sims 500  --preferred_actions --seed 123
</code></pre>

<p>To run the Tiger problem with SARSA: </p>

<pre><code>./main.py --env TigerProblem --solver SARSA --max_steps 5 --epsilon_start 0.5 --n_runs 100 --seed 123
</code></pre>

<p>See <code>pompdy/README.md</code> for details about implementing new POMDP benchmark problems.</p>

<h2>
<a id="todo" class="anchor" href="#todo" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>TODO</h2>

<ul>
<li>[ ] Random baseline solver</li>
<li>[ ] Add more unit tests</li>
<li>[ ] Add additional benchmark problems </li>
<li>[ ] Continuous-action/state space POMDPs</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/pemami4911/POMDPy">POMDPy</a> is maintained by <a href="https://github.com/pemami4911">pemami4911</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("82749305");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
